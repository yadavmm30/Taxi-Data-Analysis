---
title: "Regression_Model"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown


```{r import_data}
taxi <- read.csv("../Data/taxidata_processed_project2.csv")
any(is.na(taxi))   # why true
taxi <- na.omit(taxi)
str(taxi)
```

We are working with a large data set, but only few features are of particular interest to our analysis. So, we are going to  extract only the ones that we need for operational efficiency. 

```{r features}


taxi_sub <- subset(taxi, select = c("tip_fare_ratio", "passenger_count", "fare_amount", "VendorID", "Borough_pu", "Borough_do", "pickup_period", "drop_period", "trip_distance", "trip_duration"))

# taxi_sub <- subset(taxi, select = c("tip_fare_ratio", "passenger_count", "trip_distance", "fare_amount")) 
# glimpse(taxi_sub)

# convert vendor_id to factor
taxi_sub$VendorID <- as.factor(taxi_sub$VendorID)
indep_var <- c("passenger_count", "trip_distance", "fare_amount")
taxi_sub[indep_var] <- scale(taxi_sub[indep_var], center = TRUE, scale = TRUE)
str(taxi_sub)


```

```{r  modelling}
set.seed(1)

# splitting data
row.number <- sample(1:nrow(taxi_sub), 0.7*nrow(taxi_sub))

# training & testing data
train = taxi_sub[row.number, ]
test = taxi_sub[-row.number, ]

dim(train)
dim(test)


```

Observations from summary(lin_model):

1. Is there a relationship between predictor & response variable?
This can be answered using F-stat which defines the collective effect of all predictor variables on the response variable. In our case this value is 4008 (far greater than 1) so it can be concluded that there is a relationship between predictor and response variable.

2. Which of predictor variables are significant?
The lesser the p-value, the more significant the variable is so trip_distance, fare_amount and tip_amount are the ones that we should keep. The same can be confirmed through significance codes (*s).

3. Is this model good?
R^2 values (amount of variance explained) close to 1 indicate a good fit. In our case it is 0.65 or 65% so model is not such a good fit.

```{r lin_reg}
library(ggplot2)

# exploring the normality of response variable
ggplot(taxi_sub, aes(tip_fare_ratio)) + geom_histogram(fill = "green")

lin_model <- lm(tip_fare_ratio ~ ., data = train )
summary(lin_model)
```

Linear regression gave us an accuracy of 65% so lets try polynomial regression and see if we can get better results.
https://datascienceplus.com/fitting-polynomial-regression-r/

```{r poly_reg}
poly_model <- lm(tip_fare_ratio ~ poly(trip_distance + fare_amount, 2, raw = TRUE), data = train)
summary(poly_model)
```

https://www.rstatisticsblog.com/data-science-in-action/lasso-regression/

```{r lasso}
library(glmnet)

x_vars <- model.matrix(tip_fare_ratio ~. , taxi_sub)[,-1]
y_var <- taxi_sub$tip_fare_ratio
lambda_seq <- 10^seq(2, -2, by = -.1)

# splitting data into test & train
set.seed(1)
train = sample(1:nrow(x_vars), nrow(x_vars)/2)   # 50:50 split
test = (-train)
ytest = y_var[test]


# taxi_sample <- sample(2, nrow(taxi_sub), replace=TRUE, prob=c(0.70, 0.30))
# x_train <- taxi_sub[taxi_sample==1, 2:10]
# x_test <- taxi_sub[taxi_sample==2, 2:10]
# # creating y labels
# y_train <- taxi_sub[taxi_sample==1, 1]
# y_test <- taxi_sub[taxi_sample==2, 1]

# applying lasso model by setting alpha = 1 (use alpha = 0.5 for elastic net which is a combination of ridge & lasso)
cv_output <- cv.glmnet(x_vars[train,], y_var[train], 
            alpha = 1, lambda = lambda_seq)

# identifying best lambda value
best_lam <- cv_output$lambda.min   # 0.01


# Rebuilding the model with best lamda value identified
lasso_best <- glmnet(x_vars[train,], y_var[train], alpha = 1, lambda = best_lam)
plot(lasso_best)
pred <- predict(lasso_best, s = best_lam, newx = x_vars[test,])

# Finally, we combine the predicted values and actual values to see the two values side by side
final <- cbind(y_var[test], pred)
# Checking the first six obs
head(final)

# To get the list of important variables we just need to investigate the beta coefficients of final best model.
# Inspecting beta coefficients
coef(lasso_best)

##  ?? why is it showing each each factor type category separately; only trip_duration is significant for lasso; only fare_amount & trip_duration sig for elastic net

```