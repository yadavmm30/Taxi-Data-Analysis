---
title: "Regularized_models"
author: "Steven Chao, Tanaya Kavathekar, Madhuri Yadav, Amna Gul"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
    fig_height: 4.5
    fig_width: 7
    highlight: tango
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_float: true
  pdf_document:
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
loadPkg = function(x) { if (!require(x,character.only=T, quietly =T)) { install.packages(x,dep=T,repos="http://cran.us.r-project.org"); if(!require(x,character.only=T)) stop("Package not found") } }
```

```{r loadlibraries, include=F}
loadPkg("tidyverse")
loadPkg("glmnet")
loadPkg("dplyr")
loadPkg("caret")
loadPkg("dataPreparation")
loadPkg("factoextra")
loadPkg("dummies")
loadPkg("olsrr")
loadPkg("tree")
loadPkg("rpart")
loadPkg("plyr")
loadPkg("ggplot2")
loadPkg("data.table")
loadPkg("nortest")
loadPkg("corrplot")
loadPkg("faraway")
loadPkg("data.table")
loadPkg("corrplot")
loadPkg("formattable")
loadPkg("tidyr")
if(!require(devtools)) install.packages("devtools")
devtools::install_github("kassambara/ggpubr")
loadPkg("ggpubr")
loadPkg("ggcorrplot")
loadPkg("Hmisc")
loadPkg("leaps")
loadPkg("ISLR")
loadPkg("modelr")
```

```{r udf}
# Split the data into training and test set

train_test_split = function(df_sub) {
  set.seed(123)
  training.samples <- df_sub$tip_fare_ratio %>%
    createDataPartition(p = 0.8, list = FALSE)
  
  # Build X_train, y_train, X_test, y_test
  X_train <- df_sub[training.samples, !(names(df_sub) %in% c("tip_fare_ratio", "tip_amount"))]
  y_train <- df_sub[training.samples, c("tip_fare_ratio", "tip_amount")]
  
  X_test <- df_sub[-training.samples, !(names(df_sub) %in% c("tip_fare_ratio", "tip_amount"))]
  y_test <- df_sub[-training.samples, c("tip_fare_ratio", "tip_amount")]
  
  # create list of the return variables
  dfs_list <- list("X_train" = X_train, "y_train" = y_train, "X_test" = X_test, "y_test" = y_test) 
  return(dfs_list)
}

# Accuracy metric MAPE (Mean absolute percentage error)
mape <- function(actual,pred){
           mape <- mean(abs((actual - pred)/actual))*100
           return (mape)
}


corr_eqn <- function(x,y, digits = 2) {
  corr_coef <- round(cor(x, y), digits = digits)
  paste("italic(r) == ", corr_coef)
}

# Plot cooks distance
cooks_distance <- function(df, model){
  
  cooksd <- cooks.distance(model)
  sample_size <- nrow(df)
  plot(cooksd, pch="*", cex=2, main="Influential Obs by Cooks distance")  # plot cook's distance
  abline(h = 4/sample_size, col="red")  # add cutoff line
  text(x=1:length(cooksd)+1, y=cooksd, labels=ifelse(cooksd>4/sample_size, names(cooksd),""), col="red")  # add label
  
}

# removing outlies
influential_points <- function(df_out, model) {
  cooksd <- cooks.distance(model)
  sample_size <- nrow(df_out)
  # influential row numbers
  influential <- as.numeric(names(cooksd)[(cooksd > (4/sample_size))])
  print(length(influential))
  df_out <- df_out[-influential, ]
  return (df_out)
}

```


# Data

First of all, we load data into R and clean (preprocess) it so that it can be used for further analysis. Main steps  performed during cleaning data include filtering irrelevant columns and values. Relevant columns were then formatted to their correct type. Also we checked if data frame contains any NAs or duplicate values which might affect the final results.

```{r data}
#read_file
df <- read.csv("../Data/taxidata_processed_project2.csv")
# remove zero passenger count
df <- df %>% filter(passenger_count>0)

# select the required columns
df_sub <- df[,c("tip_fare_ratio", "tip_amount", "VendorID",  "passenger_count", "trip_distance", "fare_amount", "congestion_surcharge", "Borough_pu", "Borough_do", "pickup_period", "drop_period", "trip_duration")]

print(dim(df_sub))

# checking for NAs
# any(is.na(df_sub))    # false
# removing duplicate rows
df_sub <- distinct(df_sub)

# convert vendor to factor
df_sub$VendorID <- as.factor(df_sub$VendorID)

# extracting numerical_col
condition <- (!names(df_sub) == "tip_fare_ratio") & (!sapply(df_sub, class) == "factor")

```

# EDA

Once we have cleaned our data, we start exploratory data analysis by seeking if there exists any kind of relationship between our dependent and indenpedent numerical variables. For this step, we use Pearson's correlation method to indicate the extent to which two variables are linearly related. Here, y-variable is tip_fare_ratio.

```{r correlation1}
tip_fare_ratio_cor <- cor(df_sub[,condition], df_sub[,c("tip_fare_ratio")], method = c("pearson"))

tip_fare_ratio_cor

corrplot(cor(df_sub[,(!sapply(df_sub, class) == "factor")]),type="upper", method = "number", tl.col="black")

```

The results show that trip distance, fare amount, and trip duration are negatively (and weakly) correlated whereas Passenger count and congestion surcharge are not correlated at all to tip_fare_ratio.

Here is the another correlation. This time we choose tip_amount as our dependent variable.

```{r correlation2}
cor(df_sub[,condition], df_sub[,c("tip_amount")], method = c("pearson"))
```

This time we get stronger and positive correlation coefficients between tip amount and trip distance, fare amount, and trip duration variables. Passenger count and congestion surcharge, however are not correlated with the tip amount. 

The same relationship can be visually confirmed through scatter plots below:

Below are the scatter plot along with correlation and regression line for numerical variables

For tip amount
```{r scatterplots2}

Q1 <- ggplot(df_sub, aes(x=trip_distance, y=tip_amount)) +
  geom_point(color = "blue")+
  geom_smooth(method=lm, color = "black") +
  labs(title="Variation in trip distance and tip amount",
       x="Trip distance", y = "Tip amount") +
  geom_text(x = 23, y = 40, label = corr_eqn(df_sub$trip_distance,
                             df_sub$tip_amount), parse = TRUE)


Q2 <- ggplot(df_sub, aes(x=trip_duration, y=tip_amount)) +
  geom_point(color = "red")+
  geom_smooth(method=lm) +
  labs(title="Variation in trip duration and tip amount",
       x="Trip duration", y = "Tip amount")+
  geom_text(x = 30, y = 40, label = corr_eqn(df_sub$trip_duration,
                             df_sub$tip_amount), parse = TRUE)


Q3 <- ggplot(df_sub, aes(x=congestion_surcharge, y=tip_amount)) +
  geom_point(color = "red")+
  geom_smooth(method=lm) +
  labs(title="Variation in congestion surcharge and tip amount",
       x="Congestion surcharge", y = "Tip amount")+
  geom_text(x = 2, y = 40, label = corr_eqn(df_sub$congestion_surcharge,
                             df_sub$tip_amount), parse = TRUE)

Q4 <- ggplot(df_sub, aes(x=passenger_count, y=tip_amount)) +
  geom_point(color = "red")+
  geom_smooth(method=lm) +
  labs(title="Variation in passenger count and tip amount",
       x="Passenger count", y = "Tip amount")+
  geom_text(x = 2, y = 40, label = corr_eqn(df_sub$passenger_count,
                             df_sub$tip_amount), parse = TRUE)
ggarrange(Q1, Q2, Q3,Q4 + rremove("x.text"),
          ncol = 2, nrow = 2)

``` 


Below are the scatter plot along with correlation and regression line for numerical variables

For tip fare ratio
```{r scatterplots}

Q1 <- ggplot(df_sub, aes(x=trip_distance, y=tip_fare_ratio)) +
  geom_point(color = "blue")+
  geom_smooth(method=lm, color = "black") +
  labs(title="Variation in trip distance and tip fare ratio",
       x="Trip distance", y = "Tip fare ratio") +
  geom_text(x = 23, y = 0.4, label = corr_eqn(df_sub$trip_distance,
                             df_sub$tip_fare_ratio), parse = TRUE)

Q2 <- ggplot(df_sub, aes(x=trip_duration, y=tip_fare_ratio)) +
  geom_point(color = "red")+
  geom_smooth(method=lm) +  labs(title="Variation in trip duration and tip fare ratio",
       x="Trip duration", y = "Tip fare ratio") +
  geom_text(x = 30, y = 0.4, label = corr_eqn(df_sub$trip_duration,
                             df_sub$tip_fare_ratio), parse = TRUE)

Q3 <- ggplot(df_sub, aes(x=congestion_surcharge, y=tip_fare_ratio)) +
  geom_point(color = "red")+
  geom_smooth(method=lm) +  labs(title="Variation in congestion surcharge and tip fare ratio",
       x="Congestion surcharge", y = "Tip fare ratio") +
  geom_text(x = 2, y = 0.4, label = corr_eqn(df_sub$congestion_surcharge,
                             df_sub$tip_fare_ratio), parse = TRUE)

Q4 <- ggplot(df_sub, aes(x=passenger_count, y=tip_fare_ratio)) +
  geom_point(color = "red")+
  geom_smooth(method=lm) +
  labs(title="Variation in passenger count and fip fare ratio",
       x="Passenger count", y = "Tip amount")+
  geom_text(x = 2, y = 40, label = corr_eqn(df_sub$passenger_count,
                             df_sub$tip_fare_ratio), parse = TRUE)

ggarrange(Q1, Q2, Q3,Q4 + rremove("x.text"),
          ncol = 2, nrow = 2)
```

Normality check for tip fare ratio
```{r normality check of processed data, echo=T, include=T}
#ggplot histogram of tip_fare_ratio for processed df
df_sub %>%
  ggplot(aes(x=tip_fare_ratio)) +
  geom_histogram(aes(y =..density..),  colour = "black", fill = "#66B2FF", binwidth = 0.01) + 
  stat_function(fun = dnorm, args = list(mean = mean(df_sub$tip_fare_ratio), sd = sd(df_sub$tip_fare_ratio))) + ggtitle("Distribution of NYC Taxi Tip fare ratio Data Post-Outlier Removal")
```

Normality check for tip amount
```{r }
df_sub %>%
  ggplot(aes(x=tip_amount)) +
  geom_histogram(aes(y =..density..),  colour = "black", fill = "#66B2FF", binwidth = 0.05) + 
  stat_function(fun = dnorm, args = list(mean = mean(df_sub$tip_amount), sd = sd(df_sub$tip_amount))) + ggtitle("Distribution of NYC Taxi Tip Data Post-Outlier Removal")
```



# Model building

## Test train split

To avoid introducing a bias in test using train-data, the train-test split should be performed before (most) data preparation steps for instance scaling.

To simulate a train and test set we are going to split randomly this data set into 80% train and 20% test.

```{r split the data}
# one hot encoding for factor columns
sub_factor_col <- (!(names(df_sub) %in% c("tip_fare_ratio", "tip_amount"))) & (sapply(df_sub, class) == "factor")
new_df_sub <- dummy.data.frame(df_sub[,c(sub_factor_col)],  sep="_")

# add underscore if space in colname
names(new_df_sub) <- gsub(" ", "_", names(new_df_sub))

com_df_sub <- cbind(df_sub[,c((!sapply(df_sub, class) == "factor"))], new_df_sub)

#train and test split (into 4 modules (i.e. X_train, y_train (80%) & X_test, y_test (20%))
splitted_dfs <- train_test_split(com_df_sub)
```

## Scaling variables

After splitting, we need to scale the numerical variables in our test and train datasets because the magnitude of the values might not necessarily be proportional. So lets calculate the mean and standard deviation of each numerical column for comparison purposes.

```{r scale parameter}
scales <- build_scales(dataSet = splitted_dfs["X_train"]$X_train, cols = c(names(df_sub[,condition])), verbose = TRUE)
print(scales)
```

All the variables has different means and std hence we need to scale all the variables present above.

```{r scale_all}
X_train <- fastScale(dataSet = splitted_dfs["X_train"]$X_train, scales = scales, verbose = TRUE)
X_test <- fastScale(dataSet = splitted_dfs["X_test"]$X_test, scales = scales, verbose = TRUE)
```

Bind the columns to get one train and test set 
```{r bind}
train <- cbind(X_train, data.frame("tip_fare_ratio" = splitted_dfs["y_train"]$y_train['tip_fare_ratio'], "tip_amount" = splitted_dfs["y_train"]$y_train['tip_amount']))
taxipro <- train

test <- cbind(X_test, data.frame("tip_fare_ratio" = splitted_dfs["y_test"]$y_test['tip_fare_ratio'], "tip_amount" = splitted_dfs["y_test"]$y_test['tip_amount']))

```

## Principal component analysis

We have to use one hot encoding to convert factor variables into numerical variables
```{r pca}
pr.out =prcomp(X_train, scale = F)
summary(pr.out)
pr.out$rotation[1:5,1:7]

dim(pr.out$x)

biplot(pr.out)

```


```{r }
prop_varex <- pr.out$sdev*2/sum(pr.out$sdev*2)

plot(prop_varex, xlab = "Principal Component",
             ylab = "Proportion of Variance Explained",
             type = "b")


plot(cumsum(prop_varex), xlab = "Principal Component",
              ylab = "Cumulative Proportion of Variance Explained",
              type = "b")
```

### Tip Fare Ratio
```{r pca_tipfareratio}
#add a training set with principal components

pca_train <- data.frame("tip_fare_ratio" = splitted_dfs["y_train"]$y_train['tip_fare_ratio'], pr.out$x)[,1:8]

#transform test into PCA
test.data <- predict(pr.out, newdata = X_test)
test.data <- as.data.frame(test.data)

model <- lm(tip_fare_ratio ~ ., data = pca_train)
summary(model)

# predictions
predictions <- predict(model, test.data)

# Model performance metrics
results_df <- data.frame(
  technique = "PCR",
  dependent = "tip_fare_ratio",
  mape = mape(test$tip_fare_ratio, predictions),
  Rsquare = caret::R2(predictions, test$tip_fare_ratio)
)

# ggplot(test, aes(x =test$fare_amount ,y = test$tip_fare_ratio)) +
#   geom_point() +
#   geom_point(aes(y = predictions), shape = 1, color = "blue") +
#   labs(title="Actual & Predicted Values",
#        x="Fare amount ", y = "Tip fare ratio")

# ggplot(test, aes(y =predictions ,x = test$tip_fare_ratio)) +
#   geom_point() +
#   labs(title="Actual & Predicted Values",
#        x="Actual Tip amount", y = "Predicted Tip amount")

```

### Tip amount
```{r pca_tip}
#add a training set with principal components

pca_train <- data.frame("tip_amount" = splitted_dfs["y_train"]$y_train['tip_amount'], pr.out$x)[,1:8]

#transform test into PCA
test.data <- predict(pr.out, newdata = X_test)
test.data <- as.data.frame(test.data)

model <- lm(tip_amount ~ ., data = pca_train)
summary(model)

# predictions
predictions <- predict(model, test.data)

# Model performance metrics
results_df <- rbind(results_df, data.frame(
  technique = "PCR",
  dependent = "tip_amount",
  mape = mape(test$tip_amount, predictions),
  Rsquare = caret::R2(predictions, test$tip_amount)
))

ggplot(test, aes(y =predictions ,x = test$tip_amount)) +
  geom_point() +
  labs(title="Actual & Predicted Values",
       x="Actual Tip amount", y = "Predicted Tip amount")

```


# Modeling

## Linear Models

### Uni and Multivariate modeling with high Pearson Correlation values for 'Tip_Fare_Ratio'

Let us Start building our linear model with first 3 high Pearson Correlation values for 'Tip_Fare_Ratio'

```{r }

#Taking best three variables correlated with tip_fare ratio based on Pearson Correlation

#linear model of tip_fare_ratio ~ trip_duration
fit1 <- lm(tip_fare_ratio ~ fare_amount, data = taxipro )
summary(fit1)
# vif(fit1)
# plot(fit1)

#linear model of tip_fare_ratio ~ trip_duration+fare_amount
fit2 <- lm(tip_fare_ratio ~ fare_amount+trip_duration, data = taxipro )
summary(fit2)
# vif(fit2)
# plot(fit2)

#linear model of tip_fare_ratio ~ trip_duration+fare_amount+trip_distance
fit3 <- lm(tip_fare_ratio ~ fare_amount+trip_duration+trip_distance, data = taxipro )
summary(fit3)
vif(fit3)
plot(fit3)
```

The model graphs look good. So let us perform ANOVA test on all the three models.

```{r, include=TRUE}
#perform ANOVA to compare three models built
anova(fit1,fit2,fit3)
```

We observe that p is > 0.05 for fit3 implies fit2 and fit3 are same.

Below is the graph for predicted vs Actual values of tip_fare_ratio

```{r, include=TRUE}
#Prediction
model.final.pred <- add_predictions(test,fit3)
# head(model.final.pred)
ggplot(model.final.pred,aes(tip_fare_ratio,pred))+geom_point(aes(tip_fare_ratio,pred))+geom_line(aes(pred), colour="red", size=1)

# Model performance metrics
results_df <- rbind(results_df, data.frame(
  technique = "Linear(3 best cor values)",
  dependent = "tip_fare_ratio",
  mape = mape(model.final.pred$tip_fare_ratio, model.final.pred$pred),
  Rsquare = caret::R2(model.final.pred$pred, model.final.pred$tip_fare_ratio)
))

```

Since the results are not satisfactory we perform step by feature selection.
Below is the tip_fare_ratio ~ . step by feature selection with Adjusted R^2 scaling

```{r step_by_feature_selection, include= TRUE}

mod_tip_ratio <- regsubsets(tip_fare_ratio ~ .-tip_amount, data = train, nvmax = 14, nbest = 1, method = "backward")
#plot(mod_tip_ratio, scale = "Cp", main = "Cp")
plot(mod_tip_ratio, scale = "adjr2", main = "Adjusted R^2")
#plot(mod_tip_ratio, scale = "r2", main = "R^2")
# plot(mod_tip_ratio, scale = "bic", main = "BIC")
```

Below is the Summary from Lm with First 3 features selected with Linear model.
```{r, Include= TRUE}

#Let us select first three features selected by feature selection function above.
fit_feature <- lm(tip_fare_ratio ~ trip_duration+congestion_surcharge+Borough_do_Unknown, data = taxipro )
summary(fit_feature)
# vif(fit_feature)
plot(fit_feature)
```

Below is the graph for predicted vs Actual values of tip_fare_ratio
```{r, include=TRUE}

#Prediction
model.final.pred <- add_predictions(test,fit_feature)
# head(model.final.pred)
ggplot(model.final.pred,aes(tip_fare_ratio,pred))+geom_point(aes(tip_fare_ratio,pred))+geom_line(aes(pred), colour="red", size=1)

# Model performance metrics
results_df <- rbind(results_df, data.frame(
  technique = "Linear-Stepwise",
  dependent = "tip_fare_ratio",
  mape = mape(model.final.pred$tip_fare_ratio, model.final.pred$pred),
  Rsquare = caret::R2(model.final.pred$pred, model.final.pred$tip_fare_ratio)
))

```

To further improve the model now we use tip_amount instead of Tip_Fare_Ratio since we did not get any significant improvement in adj R^2 value.

### Uni and Multivariate modeling with high Pearson Correlation values for 'Tip_Amount'

Let us Start building our linear model with tip amount instead of tip fare ratio with first 3 high Pearson Correlation values for 'Tip_Amount'

```{r, include= TRUE}

#Taking best three variables correlated with tip_fare ratio

#linear model of tip_amount ~ trip_duration
fit1_ta <- lm(tip_amount ~ fare_amount, data = taxipro )
summary(fit1_ta)
# vif(fit1_ta)
# plot(fit1_ta)

#linear model of tip_amount ~ trip_duration+fare_amount
fit2_ta <- lm(tip_amount ~ fare_amount+trip_duration, data = taxipro )
summary(fit2_ta)
# vif(fit2_ta)
# plot(fit2_ta)

#linear model of tip_amount ~ trip_duration+fare_amount+trip_distance
fit3_ta <- lm(tip_amount ~ fare_amount+trip_duration+trip_distance, data = taxipro )
summary(fit3_ta)
# vif(fit3_ta)
plot(fit3_ta)

```

The model graphs look good. So let us perform ANOVA test on all the three models.

```{r, include=TRUE}
#perform ANOVA to compare three models built
anova(fit1_ta,fit2_ta,fit3_ta)
```

We observe that p is > 0.05 for fit2 implies fit1 and fit2 are same.

Below is the graph for predicted vs Actual values of tip_fare_ratio

```{r, include=TRUE}
model.final.pred <- add_predictions(test,fit3_ta)
# head(model.final.pred)
ggplot(model.final.pred,aes(tip_amount,pred))+geom_point(aes(tip_amount,pred))+geom_line(aes(pred), colour="red", size=1)

# Model performance metrics
results_df <- rbind(results_df, data.frame(
  technique = "Linear(3 best cor values)",
  dependent = "tip_amount",
  mape = mape(model.final.pred$tip_amount, model.final.pred$pred),
  Rsquare = caret::R2(model.final.pred$pred, model.final.pred$tip_amount)
))
```

Since the results are not satisfactory we perform step by feature selection.
Below is the tip_fare_ratio ~ . step by feature selection with Adjusted R^2 scaling

```{r step_by_feature_selection1, include= TRUE}

mod_tip_ratio <- regsubsets(tip_amount ~ .-tip_fare_ratio, data = train, nvmax = 14, nbest = 1, method = "backward")
# plot(mod_tip_ratio, scale = "Cp", main = "Cp")
plot(mod_tip_ratio, scale = "adjr2", main = "Adjusted R^2")
# plot(mod_tip_ratio, scale = "r2", main = "R^2")
# plot(mod_tip_ratio, scale = "bic", main = "BIC")

```


Below is the Summary from Lm with First 3 features selected with Linear model.

```{r, include=TRUE}
#Let us select first three features selected by feature selection function above.
fit_feature_ta <- lm(tip_amount ~ fare_amount+congestion_surcharge+Borough_do_Bronx, data = taxipro )
summary(fit_feature_ta) 
# vif(fit_feature_ta)
# plot(fit_feature_ta)

# #perform ANOVA to compare three models built
# anova(fit3_ta,fit_feature_ta)
```

Below is the graph for predicted vs Actual values of tip_amount
```{r, include=TRUE}

model.final.pred <- add_predictions(test,fit_feature_ta)
# head(model.final.pred)
ggplot(model.final.pred,aes(tip_amount,pred))+geom_point(aes(tip_amount,pred))+geom_line(aes(pred), colour="red", size=1)

# Model performance metrics
results_df <- rbind(results_df, data.frame(
  technique = "Linear-Stepwise",
  dependent = "tip_amount",
  mape = mape(model.final.pred$tip_amount, model.final.pred$pred),
  Rsquare = caret::R2(model.final.pred$pred, model.final.pred$tip_amount)
))

```

Below are the results of lm(tip_amount ~ .-fare_amount)
```{r lm-fare_amount, include= TRUE}
#Let us select first three features selected by feature selection function above.
fit_without_fare_amount <- lm(tip_amount ~ .-fare_amount-tip_fare_ratio, data = taxipro )
summary(fit_without_fare_amount) 
# vif(fit_without_fare_amount)
# plot(fit_feature_ta)

# #perform ANOVA to compare three models built
# anova(fit3_ta,fit_without_fare_amount)


model.final.pred <- add_predictions(test,fit_without_fare_amount)
# head(model.final.pred)
ggplot(model.final.pred,aes(tip_amount,pred))+geom_point(aes(tip_amount,pred))+geom_line(aes(pred), colour="red", size=1)

```


Let build linear models on tip fare ratio: 
## OLS

### Tip fare ratio

```{r ols_tipfareratio}

model <- lm(tip_fare_ratio ~ .-tip_amount, data = train)
summary(model)
vif(model)
# plot(model)
```
As you can see from the summary r square `r format( summary(model)$r.squared )` and adj r square is really low `r format( summary(model)$adj.r.squared)`

The VIF factor is also 1. 

Select only significant coeff:
```{r ols_sig}
model <- lm(tip_fare_ratio ~ fare_amount + congestion_surcharge + trip_duration +Borough_pu_Queens + Borough_do_EWR + drop_period_Evening, data = train)
summary(model)
vif(model)

# predictions
predictions <- predict(model, test)

# Model performance metrics
results_df <- rbind(results_df, data.frame(
  technique = "Linear",
  dependent = "tip_fare_ratio",
  mape = mape(test$tip_fare_ratio, predictions),
  Rsquare = caret::R2(predictions, test$tip_fare_ratio)
))

```
No significant improvement even factor choosing significant variables. 

From the plot we can see there are some variables outside cooks distance. Lets remove those points and see how the model performs. 
```{r cooksdistance removed}
df_out <- influential_points(train, model)
model_rmcook <- lm(tip_fare_ratio ~ fare_amount, data = df_out)
summary(model_rmcook)
vif(model_rmcook)

# predictions
predictions <- predict(model_rmcook, test)

# Model performance metrics
results_df <- rbind(results_df, data.frame(
  technique = "Linear-treated outlier",
  dependent = "tip_fare_ratio",
  mape = mape(test$tip_fare_ratio, predictions),
  Rsquare = caret::R2(predictions, test$tip_fare_ratio)
))


# sample_size <- nrow(df_sub)
# plot(cooksd, pch="*", cex=2, main="Influential Obs by Cooks distance")  # plot cook's distance
# abline(h = 15/sample_size, col="red")  # add cutoff line
# text(x=1:length(cooksd)+1, y=cooksd, labels=ifelse(cooksd>4/sample_size, names(cooksd),""), col="red")  # add label
```
After removal of the outliers from the data there is no improvement in the values for tip fare ratio

### Tip amount
Similary check a model with tip amount and significant variables decided from the tip ratio
```{r ols_sig_tip}
model_tip_amount <- lm(tip_amount ~ fare_amount + congestion_surcharge + trip_duration +Borough_pu_Queens + Borough_do_EWR + drop_period_Evening, data = train)
summary(model_tip_amount)
vif(model_tip_amount)

# predictions
predictions <- predict(model_tip_amount, test)

# Model performance metrics
results_df <- rbind(results_df, data.frame(
  technique = "Linear",
  dependent = "tip_amount",
  mape = mape(test$tip_amount, predictions),
  Rsquare = caret::R2(predictions, test$tip_amount)
))

# plot(model_tip_amount)
```
As you can see from the summary r square `r format( summary(model_tip_amount)$r.squared )` and adj r square `r format( summary(model_tip_amount)$adj.r.squared)` are really good. Also fare amount is the significant variable

The VIF factor is also 1. 

From the plot we can see there are some variables outside cooks distance. Lets remove those points and see how the model performs. 
```{r cooksdistance_removed_tip_amount}
df_out <- influential_points(train, model_tip_amount)
dim(df_out)

model_tip_amountrmcook <- lm(tip_amount ~ fare_amount + congestion_surcharge + trip_duration +Borough_pu_Queens + Borough_do_EWR + drop_period_Evening, data = df_out)
summary(model_tip_amountrmcook)
vif(model_tip_amountrmcook)

# predictions
predictions <- predict(model_tip_amountrmcook, test)

# Model performance metrics
results_df <- rbind(results_df, data.frame(
  technique = "Linear-treated outlier",
  dependent = "tip_amount",
  mape = mape(test$tip_amount, predictions),
  Rsquare = caret::R2(predictions, test$tip_amount)
))


# sample_size <- nrow(df_sub)
# plot(cooksd, pch="*", cex=2, main="Influential Obs by Cooks distance")  # plot cook's distance
# abline(h = 15/sample_size, col="red")  # add cutoff line
# text(x=1:length(cooksd)+1, y=cooksd, labels=ifelse(cooksd>4/sample_size, names(cooksd),""), col="red")  # add label
```
After removal of the outliers from the data there is no improvement in the values for tip fare ratio but residual error has improved 

## Stepwise regression
```{r stepwise}

# model <- lm(tip_fare_ratio ~ .-tip_amount, data = train)
# step_lm_tip <- ols_step_all_possible(model)
# # plot(k)
# plot(step_lm_tip, scale = "adjr2", main = "Adjusted R^2")
# plot(step_lm_tip, scale = "r2", main = "R^2")
# model <- lm(tip_amount ~ .-tip_fare_ratio, data = train)
# k <- ols_step_all_possible(model)
# plot(k)

```

## Ridge
### Tip Fare Ratio
Lets see if ridge improves results with all variables
```{r ridge_tipfareratio}
x=model.matrix(tip_fare_ratio~.-tip_amount,train)[,-1]
y = train %>%
  select(tip_fare_ratio) %>%
  unlist() %>%
  as.numeric()

set.seed(123)
cv_lamda = cv.glmnet(x, y, alpha = 0, standardize = FALSE)
# Display the best lambda value
cv_lamda$lambda.min

# Fit the final model on the training data
ridge_model <- glmnet(x, y, alpha = 0, lambda = cv_lamda$lambda.min, standardize = FALSE)

# Make predictions on the test data
x.test <- model.matrix(tip_fare_ratio ~.-tip_amount, test)[,-1]
predictions <- ridge_model %>% predict(x.test) %>% as.vector()

# Model performance metrics
results_df <- rbind(results_df, data.frame(
  technique = "Ridge",
  dependent = "tip_fare_ratio",
  mape = mape(test$tip_fare_ratio, predictions),
  Rsquare = caret::R2(predictions, test$tip_fare_ratio)
))


# Display regression coefficients
coef(ridge_model)
plot(cv_lamda)

ggplot(test, aes(x =test$tip_fare_ratio ,y = predictions)) +
  geom_point() +
  labs(title="Actual & Predicted Values",
       x="Fare amount ", y = "Tip amount")

```

The lowest point in the curve indicates the optimal lambda: the log value of lambda that best minimised the error in cross-validation.

### Tip amount
```{r ridge_tip}
x=model.matrix(tip_amount~.-tip_fare_ratio,train)[,-1]
y = train %>%
  select(tip_amount) %>%
  unlist() %>%
  as.numeric()

set.seed(123)
cv_lamda = cv.glmnet(x, y, alpha = 0, standardize = FALSE)
# Display the best lambda value
cv_lamda$lambda.min


# Fit the final model on the training data
ridge_model <- glmnet(x, y, alpha = 0, lambda = cv_lamda$lambda.min, standardize = FALSE)
# Display regression coefficients
coef(ridge_model)
plot(cv_lamda)

# Make predictions on the test data
x.test <- model.matrix(tip_amount~.-tip_fare_ratio, test)[,-1]
predictions <- ridge_model %>% predict(x.test) %>% as.vector()

# Model performance metrics
results_df <- rbind(results_df, data.frame(
  technique = "Ridge",
  dependent = "tip_amount",
  mape = mape(test$tip_amount, predictions),
  Rsquare = caret::R2(predictions, test$tip_amount)
))

# check <- data.frame(predictions, test$tip_amount)
ggplot(test, aes(x =test$tip_amount ,y = predictions)) +
  geom_point() +
  labs(title="Actual & Predicted Values",
       x="Fare amount ", y = "Tip amount")

```

## Lasso
### Tip fare ratio
```{r lasso_tipfareratio}
x=model.matrix(tip_fare_ratio~.-tip_amount,train)[,-1]
y = train %>%
  select(tip_fare_ratio) %>%
  unlist() %>%
  as.numeric()

# Find the best lambda using cross-validation
set.seed(123) 
lasso_cv <- cv.glmnet(x, y, alpha = 1, standardize = FALSE)
# Display the best lambda value
lasso_cv$lambda.min

plot(cv_lamda)

# Fit the final model on the training data
lasso_model <- glmnet(x, y, alpha = 1, lambda = lasso_cv$lambda.min, standardize = FALSE)
# Dsiplay regression coefficients
coef(lasso_model)

# # Make predictions on the test data
x.test <- model.matrix(tip_fare_ratio ~.-tip_amount, test)[,-1]
predictions <- lasso_model %>% predict(x.test) %>% as.vector()

# Model performance metrics
results_df <- rbind(results_df, data.frame(
  technique = "Lasso",
  dependent = "tip_fare_ratio",
  mape = mape(test$tip_fare_ratio, predictions),
  Rsquare = caret::R2(predictions, test$tip_fare_ratio)
))

ggplot(test, aes(x =test$tip_fare_ratio ,y = predictions)) +
  geom_point() +
  labs(title="Actual & Predicted Values",
       x="Fare amount ", y = "Tip amount")

```



## Tip amount
```{r lasso_tip}
x=model.matrix(tip_amount ~.-tip_fare_ratio,train)[,-1]
y = train %>%
  select(tip_amount) %>%
  unlist() %>%
  as.numeric()

# Find the best lambda using cross-validation
set.seed(123) 
lasso_cv <- cv.glmnet(x, y, alpha = 1, standardize = FALSE)
# Display the best lambda value
lasso_cv$lambda.min

# Fit the final model on the training data
lasso_model <- glmnet(x, y, alpha = 1, lambda = lasso_cv$lambda.min, standardize = FALSE)
# Dsiplay regression coefficients
coef(lasso_model)

# # Make predictions on the test data
x.test <- model.matrix(tip_amount ~.-tip_fare_ratio, test)[,-1]
predictions <- lasso_model %>% predict(x.test) %>% as.vector()

# Model performance metrics
results_df <- rbind(results_df, data.frame(
  technique = "Lasso",
  dependent = "tip_amount",
  mape = mape(test$tip_amount, predictions),
  Rsquare = caret::R2(predictions, test$tip_amount)
))

ggplot(test, aes(x =test$tip_amount ,y = predictions)) +
  geom_point() +
  labs(title="Actual & Predicted Values",
       x="Fare amount ", y = "Tip amount")
```


## Elastic Net


Elastic net can be thought of as a mixture of Lasso & Ridge models. It combines the penalties of ridge regression and lasso to get the best of both. There are two parameters to tune here lambda and alpha. First lets try with alpha = 0.5

### Tip fare ratio

```{r elnet_tipfareratio}

x=model.matrix(tip_fare_ratio~.-tip_amount,train)[,-1]
y = train %>%
  select(tip_fare_ratio) %>%
  unlist() %>%
  as.numeric()

# Find the best lambda using cross-validation
set.seed(123)
elnet_cv <- cv.glmnet(x, y, alpha = 0.5, standardize = FALSE)
# Display the best lambda value
elnet_cv$lambda.min

# Fit the final model on the training data
elnet_model <- glmnet(x, y, alpha = 0.5, lambda = elnet_cv$lambda.min, standardize = FALSE)
# Dsiplay regression coefficients
coef(elnet_model)

# # Make predictions on the test data
x.test <- model.matrix(tip_fare_ratio ~.-tip_amount, test)[,-1]
predictions <- elnet_model %>% predict(x.test) %>% as.vector()

# Model performance metrics
results_df <- rbind(results_df, data.frame(
  technique = "Elastic Net",
  dependent = "tip_fare_ratio",
  mape = mape(test$tip_fare_ratio, predictions),
  Rsquare = caret::R2(predictions, test$tip_fare_ratio)
))

ggplot(test, aes(x =test$tip_fare_ratio ,y = predictions)) +
  geom_point() +
  labs(title="Actual & Predicted Values",
       x="Fare amount ", y = "Tip amount")

```


## Tip amount

```{r elnet_tip}
x=model.matrix(tip_amount ~.-tip_fare_ratio,train)[,-1]
y = train %>%
  select(tip_amount) %>%
  unlist() %>%
  as.numeric()

# Find the best lambda using cross-validation
set.seed(123)
elnet_cv <- cv.glmnet(x, y, alpha = 0.5, standardize = FALSE)
# Display the best lambda value
elnet_cv$lambda.min

# Fit the final model on the training data
elnet_model <- glmnet(x, y, alpha = 0.5, lambda = elnet_cv$lambda.min, standardize = FALSE)
# Dsiplay regression coefficients
coef(elnet_model)

# # Make predictions on the test data
x.test <- model.matrix(tip_amount ~.-tip_fare_ratio, test)[,-1]
predictions <- elnet_model %>% predict(x.test) %>% as.vector()

# Model performance metrics
results_df <- rbind(results_df, data.frame(
  technique = "Elastic Net",
  dependent = "tip_amount",
  mape = mape(test$tip_amount, predictions),
  Rsquare = caret::R2(predictions, test$tip_amount)
))

ggplot(test, aes(x =test$tip_amount ,y = predictions)) +
  geom_point() +
  labs(title="Actual & Predicted Values",
       x="Fare amount ", y = "Tip amount")
```






### Decision Tree

#### Tip Amount

```{r dt_growtree_tip}
# Grow decision tree
taxi_tree_tip <- tree(tip_amount ~ passenger_count + trip_distance + fare_amount + congestion_surcharge + trip_duration + VendorID_1 + VendorID_2 + Borough_pu_Bronx + Borough_pu_Brooklyn + Borough_pu_Manhattan + Borough_pu_Queens + Borough_pu_Unknown + Borough_do_Bronx + Borough_do_Brooklyn + Borough_do_EWR + Borough_do_Manhattan + Borough_do_Queens + Borough_do_Staten_Island + Borough_do_Unknown + pickup_period_Afternoon + pickup_period_Evening + pickup_period_Morning + pickup_period_Night + drop_period_Afternoon + drop_period_Evening + drop_period_Morning + drop_period_Night, data = train, mindev=0.001)

# Print results
summary(taxi_tree_tip)
```

Here is the decision tree for tip amount:

```{r dt_plottree_tip, out.width='100%', out.height='100%', include = T, echo = F}
# Plot tree
#png(file="tree_tipamt.png",width=900,height=900,res=30) # Use if want to export
plot(taxi_tree_tip, main = "Decision Tree for Tip Amount") 
text(taxi_tree_tip, cex = 0.75) #2.5)
#dev.off() # Use if want to export
```


```{r dt_prunetree_tip}
# Create sequence of pruned tree sizes/errors
tip_prune_seq = prune.tree(taxi_tree_tip)

# Plot error versus plot size
plot(tip_prune_seq, main = "Error versus Decision Tree Plot Size for Tip Amount")

# Get vector of error
tip_prune_seq$dev

# Identify optimal tree where vector of error is minimized
optimal_tree_tip = which(tip_prune_seq$dev == min(tip_prune_seq$dev))

# Positions of optimal (with respect to error) trees 
min(tip_prune_seq$size[optimal_tree_tip])
```

Here is the pruned tree:

```{r dt_plotprunetree_tip, include = T, echo = F}
# Return best pruned tree with 5 leaves, evaluating error on training data 
tree_tip_prune <- prune.tree(taxi_tree_tip, best = 5)

# Plot tree
plot(tree_tip_prune, main = "Pruned Decision Tree for Tip Amount") 
text(tree_tip_prune, cex = 0.75)
```

```{r dt_cvtree_tip}
# Create sequence of CV tree sizes/errors
tip_cv_seq = cv.tree(taxi_tree_tip)

# Plot error versus plot size
plot(tip_cv_seq, main = "Error versus Decision Tree Plot Size for Tip Amount")

# Get vector of error
tip_cv_seq$dev

# Identify optimal tree where vector of error is minimized
optimal_cvtree_tip = which(tip_cv_seq$dev == min(tip_cv_seq$dev))

# Positions of optimal (with respect to error) trees 
best_leaves_cv_tip = min(tip_cv_seq$size[optimal_cvtree_tip])
best_leaves_cv_tip
```

Here is the pruned tree by 10-fold CV:

```{r dt_plotcvtree_tip, include = T, echo = F}
# Plot tree
tree_tip_cv = cv.tree(taxi_tree_tip, best = 5)
plot(tree_tip_cv, main = "CV Decision Tree for Tip Amount")
text(tree_tip_prune, cex = 0.5)
```

```{r dt_accuracy_tip}
# Original
# Predict test values using tree
tree_tip_pred = predict(taxi_tree_tip, newdata = test)

# Obtain MSE
tree_tip_mse = (sum((tree_tip_pred - test$tip_amount)^2)) / nrow(test)

# Print MSE
tree_tip_mse

# Model performance metrics
results_df <- rbind(results_df, data.frame(
  technique = "Decision Tree",
  dependent = "tip_amount",
  mape = mape(test$tip_amount, tree_tip_pred),
  Rsquare = caret::R2(tree_tip_pred, test$tip_amount)
))

# Pruned
# Predict test values using tree
tree_tip_pred_prune = predict(tree_tip_prune, newdata = test)

# Obtain MSE
tree_tip_mse_prune = (sum((tree_tip_pred_prune - test$tip_amount)^2)) / nrow(test)

# Print MSE
tree_tip_mse_prune

# Model performance metrics
results_df <- rbind(results_df, data.frame(
  technique = "Decision Tree (Prune)",
  dependent = "tip_amount",
  mape = mape(test$tip_amount, tree_tip_pred_prune),
  Rsquare = caret::R2(tree_tip_pred_prune, test$tip_amount)
))

# CV
# Predict test values using tree
tree_tip_pred_cv = predict(tree_tip_cv, newdata = test)

# Obtain MSE
tree_tip_mse_cv = (sum((tree_tip_pred_cv - test$tip_amount)^2)) / nrow(test)

# Print MSE
tree_tip_mse_cv

# Model performance metrics
results_df <- rbind(results_df, data.frame(
  technique = "Decision Tree (CV)",
  dependent = "tip_amount",
  mape = mape(test$tip_amount, tree_tip_pred_cv),
  Rsquare = caret::R2(tree_tip_pred_cv, test$tip_amount)
))
```


#### Tip Fare Ratio

```{r dt_growtree_ratio}
# Grow decision tree
taxi_tree_ratio <- tree(tip_fare_ratio ~ passenger_count + trip_distance + fare_amount + congestion_surcharge + trip_duration + VendorID_1 + VendorID_2 + Borough_pu_Bronx + Borough_pu_Brooklyn + Borough_pu_Manhattan + Borough_pu_Queens + Borough_pu_Unknown + Borough_do_Bronx + Borough_do_Brooklyn + Borough_do_EWR + Borough_do_Manhattan + Borough_do_Queens + Borough_do_Staten_Island + Borough_do_Unknown + pickup_period_Afternoon + pickup_period_Evening + pickup_period_Morning + pickup_period_Night + drop_period_Afternoon + drop_period_Evening + drop_period_Morning + drop_period_Night, data = train, mindev=0.001)

# Print results
summary(taxi_tree_ratio)
```

Here is the decision tree for tip ratio:

```{r dt_plottree_ratio, out.width='100%', out.height='100%', include = T, echo = F}
# Plot tree
#png(file="tree_ratio.png",width=900,height=900,res=30) # Use if want to export
plot(taxi_tree_ratio, main = "Decision Tree for Tip Ratio") 
text(taxi_tree_ratio, cex = 0.75) #2.5)
#dev.off() # Use if want to export
```


```{r dt_prunetree_ratio}
# Create sequence of pruned tree sizes/errors
ratio_prune_seq = prune.tree(taxi_tree_ratio)

# Plot error versus plot size
plot(ratio_prune_seq, main = "Error versus Decision Tree Plot Size for Tip Ratio")

# Get vector of error
ratio_prune_seq$dev

# Identify optimal tree where vector of error is minimized
optimal_tree_ratio = which(ratio_prune_seq$dev == min(ratio_prune_seq$dev))

# Positions of optimal (with respect to error) trees 
best_leaves_ratio_prune = min(ratio_prune_seq$size[optimal_tree_ratio])
best_leaves_ratio_prune
```

Here is the pruned decision tree:

```{r dt_plotprunetree_ratio, include = T, echo = F}
# Return best pruned tree with 5 leaves, evaluating error on training data 
tree_ratio_prune <- prune.tree(taxi_tree_ratio, best = 5)

# Plot pruned tree
plot(tree_ratio_prune, main = "Pruned Decision Tree for Tip Ratio") 
text(tree_ratio_prune, cex = 0.75)
```

```{r dt_cvtree_ratio}
# Create sequence of CV tree sizes/errors
ratio_cv_seq = cv.tree(taxi_tree_ratio)

# Plot error versus plot size
plot(ratio_cv_seq, main = "Error versus Decision Tree Plot Size for Tip Ratio")

# Get vector of error
ratio_cv_seq$dev

# Identify optimal tree where vector of error is minimized
optimal_cvtree_ratio = which(ratio_cv_seq$dev == min(ratio_cv_seq$dev))

# Positions of optimal (with respect to error) trees 
best_leaves_cv_ratio = min(ratio_cv_seq$size[optimal_cvtree_ratio])
best_leaves_cv_ratio
```

Here is the pruned tree by 10-fold CV:

```{r dt_plotcvtree_ratio, include = T, echo = F}
# Plot tree
tree_ratio_cv = cv.tree(taxi_tree_ratio, best = best_leaves_cv_ratio)
plot(tree_ratio_cv, main = "CV Decision Tree for Tip Ratio")
text(tree_ratio_prune, cex = 0.75)
```

```{r dt_accuracy_ratio}
# Original
# Predict test values using tree
tree_ratio_pred = predict(taxi_tree_ratio, newdata = test)

# Obtain MSE
tree_ratio_mse = (sum((tree_ratio_pred - test$tip_fare_ratio)^2)) / nrow(test)

# Print MSE
tree_ratio_mse

# Model performance metrics
results_df <- rbind(results_df, data.frame(
  technique = "Decision Tree",
  dependent = "tip_fare_ratio",
  mape = mape(test$tip_fare_ratio, tree_ratio_pred),
  Rsquare = caret::R2(tree_ratio_pred, test$tip_fare_ratio)
))

# Prune
# Predict test values using tree
tree_ratio_pred_prune = predict(tree_ratio_prune, newdata = test)

# Obtain MSE
tree_ratio_mse_prune = (sum((tree_ratio_pred_prune - test$tip_fare_ratio)^2)) / nrow(test)

# Print MSE
tree_ratio_mse_prune

# Model performance metrics
results_df <- rbind(results_df, data.frame(
  technique = "Decision Tree (Prune)",
  dependent = "tip_fare_ratio",
  mape = mape(test$tip_fare_ratio, tree_ratio_pred_prune),
  Rsquare = caret::R2(tree_ratio_pred_prune, test$tip_fare_ratio)
))

# CV
# Predict test values using tree
tree_ratio_pred_cv = predict(tree_ratio_cv, newdata = test)

# Obtain MSE
tree_ratio_mse_cv = (sum((tree_ratio_pred_cv - test$tip_fare_ratio)^2)) / nrow(test)

# Print MSE
tree_ratio_mse_cv

# Model performance metrics
results_df <- rbind(results_df, data.frame(
  technique = "Decision Tree (CV)",
  dependent = "tip_fare_ratio",
  mape = mape(test$tip_fare_ratio, tree_ratio_pred_cv),
  Rsquare = caret::R2(tree_ratio_pred_cv, test$tip_fare_ratio)
))
```


# Summary of Model results

```{r summary, include=TRUE}

results_df <-results_df[order(results_df$dependent, results_df$Rsquare),]

formattable(results_df,
            align =c("l","c","c","c","c"),
            list(`Model` = formatter(
              "span", style = ~ style(color = "grey",font.weight = "bold"))
              # `Rsquared` = color_bar("pink")
))
```
